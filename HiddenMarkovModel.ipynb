{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HiddenMarkovModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_nLVOBr9dBS"
      },
      "source": [
        "Hidden Markov Model tagging words from zen_of_python sentencens with POS tags.\n",
        "HMM matrices computed according to data from Brown Corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks74UHvHMb5p"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import this\n",
        "import codecs\n",
        "from collections import Counter\n",
        "from nltk.corpus import brown\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVfzkznlmAY-"
      },
      "source": [
        "zen_of_python = codecs.encode(this.s, 'rot13')\n",
        "zen_of_python = zen_of_python[34:]\n",
        "\n",
        "sentences = [] \n",
        "correct = []\n",
        "all_together = 0\n",
        "for sentx in sent_tokenize(zen_of_python):\n",
        "  sentences.append(word_tokenize(sentx)) \n",
        "  correct.append(pos_tag(word_tokenize(sentx)))\n",
        "  all_together += len(word_tokenize(sentx))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgvVClX7NKvS"
      },
      "source": [
        "class HMM:\n",
        "  def __init__(self, trans_prob, emiss_prob, pi, states, observations):\n",
        "    self.trans_prob = trans_prob\n",
        "    self.emiss_prob = emiss_prob\n",
        "    self.pi = pi\n",
        "    self.states_no = len(states)\n",
        "    self.observations_no = len(observations)\n",
        "    self.states = states\n",
        "    self.observations = observations\n",
        "    self.states_rev = dict(zip(self.states.values(), self.states.keys()))\n",
        "    self.eps = 1e-9\n",
        "\n",
        "  def _next_state(self, current_prob): \n",
        "    current_prob = current_prob.reshape(-1, 1)\n",
        "    x = current_prob*self.trans_prob\n",
        "    return np.amax(x, axis=0), np.argmax(x, axis=0) # computing probability for tag k in i-th step and where did we come from\n",
        "\n",
        "  def compute_best_states(self, obs):\n",
        "    parent = np.ones((self.states_no, 1))\n",
        "    for i in range(self.states_no):\n",
        "      parent[i][0] = i\n",
        "\n",
        "    if obs[0] in self.observations:  # if word is present in dictionary compute probability of comming to the first tag\n",
        "      current_prob = self.pi*self.emiss_prob[:, self.observations[obs[0]]]\n",
        "    else:\n",
        "      current_prob = self.pi*self.eps\n",
        "    for word in obs[1:]:\n",
        "      current_prob, tmp_par = self._next_state(current_prob)\n",
        "      if word in self.observations:\n",
        "        current_prob = current_prob*self.emiss_prob[:, self.observations[word]]\n",
        "      else:\n",
        "        current_prob = current_prob*self.eps\n",
        "      parent = np.concatenate([parent, tmp_par.reshape(-1, 1)], axis=1)\n",
        "\n",
        "    pos = len(obs)-1 \n",
        "    best = np.argmax(current_prob)\n",
        "    res = []\n",
        "    while(pos >= 0):\n",
        "      res.append((obs[pos], self.states_rev[best]))\n",
        "      best = int(parent[best][pos])\n",
        "      pos -= 1\n",
        "    return res"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1m5ypC5vJDj"
      },
      "source": [
        "for category in brown.categories():\n",
        "  print(category.upper())\n",
        "  category_text_tagged = brown.tagged_words(categories=category)\n",
        "  category_sents = brown.sents(categories=category)\n",
        "  delta = 0.9\n",
        "\n",
        "  \n",
        "  words, tags = map(list, zip(*category_text_tagged)) \n",
        "  words = Counter(words)\n",
        "  words = {word : i for i, word in enumerate(words.keys())}\n",
        "  words_no = len(words.keys())\n",
        "\n",
        "  tags = Counter(tags)\n",
        "  tags_freq = np.array(list(tags.values()))\n",
        "  tags_freq = tags_freq/np.sum(tags_freq)\n",
        "  tags = {tag : i for i, tag in enumerate(tags.keys())}\n",
        "  tags_no = len(tags.keys())\n",
        "  words_tags = Counter(category_text_tagged)\n",
        "\n",
        "  pi = np.zeros(tags_no, dtype=np.float32)\n",
        "  transition_matrix = np.zeros((tags_no, tags_no), dtype=np.float32)\n",
        "  emission_matrix = np.zeros((tags_no, words_no), dtype=np.float32)\n",
        "\n",
        "  for key, val in words_tags.items():\n",
        "    emission_matrix[tags[key[1]]][words[key[0]]] = val\n",
        "  emission_matrix = emission_matrix/np.sum(emission_matrix, axis=1).reshape(-1, 1)\n",
        "\n",
        "  counter = 0\n",
        "  for sent in category_sents:\n",
        "    prev_tag = \"\"\n",
        "    for i, word in enumerate(sent):\n",
        "      prev_tag = category_text_tagged[max(counter-1, 0)][1]\n",
        "      if(i == 0):\n",
        "        pi[tags[category_text_tagged[max(counter-1, 0)][1]]] += 1\n",
        "      cur_tag = category_text_tagged[counter][1]\n",
        "      transition_matrix[tags[prev_tag]][tags[cur_tag]] += 1\n",
        "      counter += 1\n",
        "\n",
        "  transition_matrix = transition_matrix/np.sum(transition_matrix, axis=1).reshape(-1, 1)  \n",
        "  transition_matrix = delta*transition_matrix + (1-delta)*tags_freq.reshape(-1,1)\n",
        "  \n",
        "  pi = tags_freq \n",
        "\n",
        "  hmm = HMM(transition_matrix, emission_matrix, pi, tags, words)\n",
        "  res = 0\n",
        "  for pos, sent in enumerate(sentences):\n",
        "    hmm_sent = hmm.compute_best_states(sent)[::-1]\n",
        "    print(hmm_sent)\n",
        "    for i in range(len(hmm_sent)):\n",
        "      if(hmm_sent[i][1] == correct[pos][i][1]):\n",
        "        res += 1\n",
        "  print(res/all_together*100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}