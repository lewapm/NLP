{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_numpy_Pan_Tadeusz.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXUyMZEB5-GF"
      },
      "source": [
        "Notebook that implements Vanilla RNN in Python. \n",
        "It's predicts letters in a poem \"Pan Tadeusz\" written by famous polish writes Adam Mickiewicz. \n",
        "Additionally it's able to craete text, that starts with \"Jam jest Jacek\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsB1I0H6zox6"
      },
      "source": [
        "!pip install autograd\n",
        "!pip install progressbar2\n",
        "import copy\n",
        "import math\n",
        "import gzip\n",
        "import random\n",
        "import autograd.numpy as np\n",
        "import progressbar\n",
        "\n",
        "from autograd import grad\n",
        "from autograd.core import getval\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEZmQZ_yzt7v"
      },
      "source": [
        "def get_data_from_file(filename):\n",
        "  file = open(filename, encoding=\"utf-8-sig\", mode=\"U\")\n",
        "  return file.read()\n",
        "\n",
        "def softmax(x):\n",
        "  x = np.exp(x - np.max(x))\n",
        "  t = np.sum(x, axis = 1)\n",
        "  return (x.T/t).T\n",
        "\n",
        "def convert_letters(input_text, alph_size, dict):\n",
        "  res = np.zeros((len(input_text), alph_size), dtype=np.float32)\n",
        "  for i in range(len(input_text)):\n",
        "    res[i][dict[input_text[i]]] = 1.0\n",
        "  return res\n",
        "\n",
        "def make_one_hot(elems, alph=83):\n",
        "  res = np.zeros((len(elems), alph), dtype=np.float32)\n",
        "  for i in (range(len(elems))):\n",
        "    res[i][int(elems[i])] = 1.0\n",
        "  return res\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkhkxIdLzl4x"
      },
      "source": [
        "class Model:\n",
        "  def __init__(self, layers, epoce, learning_rate, init_scale, alphabet_size, number_of_batches, len_of_batch):\n",
        "    self.sizes = [(layers[0], layers[1]), (layers[1], layers[1]), (layers[1], layers[1]), \\\n",
        "                  (1, layers[1]), (layers[1], layers[0]), (1, layers[0])] \n",
        "\n",
        "    self.epoce = epoce\n",
        "    self.nb = number_of_batches\n",
        "    self.lb = len_of_batch\n",
        "    self.learning_rate = learning_rate\n",
        "    self.init_scale = init_scale\n",
        "    self.alphabet_size = layers[0]\n",
        "    self.c = np.zeros((self.nb, layers[1]), dtype=np.int32) \n",
        "    self.nwg = [i*j for i,j in self.sizes]\n",
        "    tmp = np.random.uniform(-self.init_scale, self.init_scale, size=np.sum(self.nwg))\n",
        "    for i in range(len(self.nwg)-1):\n",
        "      self.nwg[i+1] += self.nwg[i]\n",
        "    self.W = np.array(tmp, dtype=np.float32)\n",
        "    \n",
        "  def _save_weights(self, filename):\n",
        "    np.save(filename, self.W)\n",
        "\n",
        "  def _load_weights(self, filename):\n",
        "    self.W = np.load(filename)\n",
        "\n",
        "  def _get_sizes(self, w):\n",
        "    tmp = getval(self.nwg)\n",
        "    ts = getval(self.sizes)\n",
        "    return  w[:tmp[0]].reshape(ts[0]), w[tmp[0]:tmp[1]].reshape(ts[1]), \\\n",
        "            w[tmp[1]:tmp[2]].reshape(ts[2]), w[tmp[2]:tmp[3]].reshape(ts[3]), \\\n",
        "            w[tmp[3]:tmp[4]].reshape(ts[4]), w[tmp[4]:].reshape(ts[5]),\n",
        "            \n",
        "\n",
        "  def _get_batches(self, input_text, nb, lb):\n",
        "    batch_len = len(input_text)//nb\n",
        "    number_of_probs = (batch_len-1)//lb\n",
        "\n",
        "    lett = np.zeros((number_of_probs, nb, lb, self.alphabet_size), dtype=np.int32)\n",
        "    res = np.zeros((number_of_probs, nb,lb, self.alphabet_size), dtype=np.int32)\n",
        "\n",
        "    for i in range(nb):\n",
        "      for j in range(number_of_probs - 1):\n",
        "        lett[j][i] = input_text[i*batch_len+j*lb:i*batch_len+(j+1)*lb]\n",
        "        res[j][i] = input_text[i*batch_len+j*lb+1:i*batch_len+(j+1)*lb+1]    \n",
        "    return lett, res\n",
        "\n",
        "  def _rnn_step(self, x, w):\n",
        "    w_x, w_hh, w_xh, b_h, w_hy, b_y = self._get_sizes(w)\n",
        "    x = np.dot(x, w_x)\n",
        "    self.c = np.tanh(np.dot(getval(self.c), w_hh) + np.dot(x, w_xh) + b_h)\n",
        "    y = np.dot(getval(self.c),w_hy) + b_y\n",
        "    return y\n",
        "    \n",
        "  def _loss(self, w, input_vec, output_vec, k):\n",
        "    loss_sum = np.array([0.0], dtype=np.float32)\n",
        "    for i in range(input_vec.shape[1]):\n",
        "      y = self._rnn_step(input_vec[:, i], w)\n",
        "      loss_sum += np.sum(np.log(softmax(y))*output_vec[:, i])\n",
        "    res = -loss_sum/(input_vec.shape[0]*input_vec.shape[1])\n",
        "    return res\n",
        "\n",
        "  def _dloss(self, w, x, y, k):\n",
        "    return grad(self._loss)(w, x, y, k)\n",
        "\n",
        "  def _valid(self, input_vec):\n",
        "    input_vec = input_vec[:-1].reshape(1, input_vec.shape[0]-1, input_vec.shape[1])\n",
        "    output_vec = input_vec[1:].reshape(1, input_vec.shape[0]-1, input_vec.shape[1])\n",
        "    loss_sum = np.array([0.0], dtype=np.float32)\n",
        "    with progressbar.ProgressBar(max_value = input_vec.shape[0]-1) as bar:\n",
        "      for i in range(input_vec.shape[0]-1):\n",
        "        bar.update(i)\n",
        "        x = np.array(input_vec[i], dtype=np.int32)\n",
        "        y = np.argmax(input_vec[i+1])\n",
        "        print(np.max(c_tmp))\n",
        "        res, c_tmp = self._rnn_step(x, self.W)\n",
        "        res = np.mean(np.log(softmax(res)), axis=0)\n",
        "        loss_sum += res[int(y)]\n",
        "      print(\"perplexity\", -loss_sum/input_vec.shape[0], np.exp(-loss_sum/input_vec.shape[0]))\n",
        "\n",
        "  def _check_jacek(self, jmj_vec, nb_to_lett):\n",
        "    self.c = np.zeros(self.c.shape, dtype=np.float32)\n",
        "    res_str = \"\"\n",
        "    res = jmj_vec[0]\n",
        "    for i in range(jmj_vec.shape[0]+200):\n",
        "      y = self._rnn_step(res, self.W)\n",
        "      y = np.mean(softmax(y), axis=0)\n",
        "      if(i < jmj_vec.shape[0]-1):\n",
        "        res = jmj_vec[i+1]\n",
        "        ix = np.argmax(jmj_vec[i+1])\n",
        "      else:\n",
        "        ix = np.random.choice(range(self.alphabet_size), p=y.ravel())\n",
        "        res = np.zeros((1, self.alphabet_size), dtype=np.int32)\n",
        "        res[0][ix] = 1\n",
        "      res_str = res_str+nb_to_lett[ix]\n",
        "    print(res_str, len(res_str))\n",
        "\n",
        "  def _train(self, input_vec, valid_vec, jmj_vec, nb_to_lett):\n",
        "    batch_len = input_vec.shape[0]//self.nb\n",
        "    number_of_probs = (batch_len-1)//self.lb\n",
        "    lett, out = self._get_batches(input_vec, self.nb, self.lb)\n",
        "    for i in range(self.epoce):\n",
        "      with progressbar.ProgressBar(max_value = number_of_probs) as bar:\n",
        "        for i in range(number_of_probs):\n",
        "          bar.update(i)\n",
        "          delta = self._dloss(self.W, lett[i], out[i], i)\n",
        "          self.W -= self.learning_rate*np.clip(delta, -6, 6)\n",
        "      self._save_weights(\"weights\")\n",
        "      self._valid(valid_vec)\n",
        "      self._check_jacek(jmj_vec, nb_to_lett)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7XbizjczyaB"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  learn_text = get_data_from_file(\"./data/rnn/learn.txt\")\n",
        "  valid_text = get_data_from_file(\"./data/rnn/v.txt\")\n",
        "  test_text = get_data_from_file(\"./data/rnn/test.txt\")\n",
        "  letters = sorted(set(learn_text+valid_text+test_text))\n",
        "  letters_dict = dict([(letters[i], i) for i in range(len(letters))])\n",
        "  nb_to_lett = dict([(i, letters[i]) for i in range(len(letters))])\n",
        "  print(len(test_text))\n",
        "  learn_vec = convert_letters(learn_text, len(letters), letters_dict)\n",
        "  valid_vec = convert_letters(valid_text, len(letters), letters_dict)\n",
        "  test_vec = convert_letters(test_text, len(letters), letters_dict)\n",
        "  jmj_vec = convert_letters(\"Jam jest Jacek\", len(letters), letters_dict)\n",
        "  print(valid_vec.shape)\n",
        "  \n",
        "  params={\n",
        "    'layers': [len(letters), 200],\n",
        "    'epoce': 15,\n",
        "    'learning_rate': 1.0,\n",
        "    'init_scale': 0.05, \n",
        "    'alphabet_size': len(letters),\n",
        "    'number_of_batches':20,\n",
        "    'len_of_batch': 20 \n",
        "  }\n",
        "  model = Model(**params)\n",
        "  model._check_jacek(jmj_vec, nb_to_lett)\n",
        "  model._train(learn_vec, valid_vec, jmj_vec, nb_to_lett)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}